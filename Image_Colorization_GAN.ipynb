{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Colorization Using CGAN","metadata":{}},{"cell_type":"markdown","source":"## Steps followed\n\n#### 1. Importing Necessary Libraries\n#### 2. Fetching The Dataset and Setting Up Input Paths\n#### 3. Defining Train and Test DataLoaders¶\n#### 4. Modeling the Conditional GAN\n#### 5. Defining Helper Functions\n#### 6. Initializing The Model\n#### 7. Training\n#### 8. Visualizing Loss Trajectory\n#### 9. Visualizing Predictions","metadata":{}},{"cell_type":"markdown","source":"## Step 1. Importing necessary libraries and Setting Device","metadata":{"id":"sOLTTspfy_aR"}},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\n\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nfrom skimage.color import rgb2lab, lab2rgb\n\nfrom tqdm import tqdm\n\nfrom datetime import datetime\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"id":"yr-NtIxs_0cI","outputId":"e0372de1-e386-44b6-8cf4-5a8c83d03d69","execution":{"iopub.status.busy":"2022-06-26T12:31:09.857234Z","iopub.execute_input":"2022-06-26T12:31:09.857724Z","iopub.status.idle":"2022-06-26T12:31:09.866123Z","shell.execute_reply.started":"2022-06-26T12:31:09.857689Z","shell.execute_reply":"2022-06-26T12:31:09.865263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2. Fetching The Dataset and Setting Up Input Paths","metadata":{"id":"bdn3zFUqy_aV"}},{"cell_type":"markdown","source":"### Installing fastai for Quickly Getting The COCO Dataset","metadata":{}},{"cell_type":"code","source":"!pip install -U fastai\nimport fastai","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:31:09.884561Z","iopub.execute_input":"2022-06-26T12:31:09.885282Z","iopub.status.idle":"2022-06-26T12:31:21.436098Z","shell.execute_reply.started":"2022-06-26T12:31:09.885249Z","shell.execute_reply":"2022-06-26T12:31:21.434832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Grabbing The Dataset in the Following Directory Structure\n<pre>\n.\n└── .fastai\n    └── data\n        └── coco_sample\n            └── train_sample\n                └── *.jpg (10,000 images in total)</pre>","metadata":{}},{"cell_type":"code","source":"from fastai.data.external import untar_data, URLs\ncoco_path = untar_data(URLs.COCO_SAMPLE)\ncoco_path = str(coco_path) + \"/train_sample\"\npaths = glob.glob(coco_path + \"/*.jpg\")\n# Setting seed for getting the same data across all train sessions \nnp.random.seed(123)\npaths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 10000 images randomly\nrand_idxs = np.random.permutation(10_000)\ntrain_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\nval_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\ntrain_paths = paths_subset[train_idxs]\nval_paths = paths_subset[val_idxs]\nprint(train_paths)","metadata":{"id":"_gSC7qAV_0cN","outputId":"410b9a09-ea5e-4372-9248-636c9cd7cf3f","execution":{"iopub.status.busy":"2022-06-26T12:31:21.438064Z","iopub.execute_input":"2022-06-26T12:31:21.438454Z","iopub.status.idle":"2022-06-26T12:31:21.556608Z","shell.execute_reply.started":"2022-06-26T12:31:21.438418Z","shell.execute_reply":"2022-06-26T12:31:21.554741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Previewing The Input Images","metadata":{}},{"cell_type":"code","source":"imageCount = 0\nfig, ax = plt.subplots(4, 4, figsize=(13,13))\nfor i in range(4):\n    for j in range(4):        \n        ax[i, j].imshow(Image.open(train_paths[imageCount]))\n        imageCount+=1","metadata":{"id":"DZ4IxBQk_0cO","outputId":"d54c3170-0c1f-4f64-c1e1-255285910581","execution":{"iopub.status.busy":"2022-06-26T12:31:21.55777Z","iopub.execute_input":"2022-06-26T12:31:21.558078Z","iopub.status.idle":"2022-06-26T12:31:23.832387Z","shell.execute_reply.started":"2022-06-26T12:31:21.558051Z","shell.execute_reply":"2022-06-26T12:31:23.831394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3. Defining Train and Test DataLoaders","metadata":{"id":"hy22jp5ey_aZ"}},{"cell_type":"code","source":"ImageSize = 256\nclass MakeDataset(Dataset):\n    def __init__(self, paths):\n        self.transforms = transforms.Compose([\n                transforms.Resize((ImageSize, ImageSize),  Image.Resampling.BICUBIC),\n                transforms.RandomHorizontalFlip(), # Added after 350th Epoch to see if Results improves\n            ])\n        self.paths=paths\n\n    def __getitem__(self, i):\n        img = Image.open(self.paths[i])\n        img = img.convert(\"RGB\")\n        img = self.transforms(img)\n        img = np.array(img)\n        imgInLAB = rgb2lab(img).astype(\"float32\")\n        imgInLAB = transforms.ToTensor()(imgInLAB)\n        L_array = imgInLAB[[0], ...] / 50. - 1.\n        ab_array = imgInLAB[[1, 2], ...] / 110.\n        return [L_array, ab_array]\n        \n    def __len__(self):\n        return len(self.paths)\n    ","metadata":{"id":"SrIQ692A_0cP","execution":{"iopub.status.busy":"2022-06-26T12:31:23.834588Z","iopub.execute_input":"2022-06-26T12:31:23.834944Z","iopub.status.idle":"2022-06-26T12:31:23.844402Z","shell.execute_reply.started":"2022-06-26T12:31:23.834905Z","shell.execute_reply":"2022-06-26T12:31:23.843435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Making dataloaders with input images transformed to L and ab image space, after resizing to 256x256","metadata":{}},{"cell_type":"code","source":"BatchSize, Workers = [16, 4]\ntrain_dl = DataLoader(MakeDataset(paths=train_paths), batch_size=BatchSize, num_workers=Workers, pin_memory=True, shuffle = True)\nval_dl = DataLoader(MakeDataset(paths=val_paths), batch_size=BatchSize, num_workers=Workers, pin_memory=True, shuffle = True)\n","metadata":{"id":"z07eYfqf_0cQ","outputId":"4bcf4c4c-a4c7-4c8b-b76e-5bae279cc75c","execution":{"iopub.status.busy":"2022-06-26T12:31:23.845639Z","iopub.execute_input":"2022-06-26T12:31:23.845983Z","iopub.status.idle":"2022-06-26T12:31:23.861237Z","shell.execute_reply.started":"2022-06-26T12:31:23.845953Z","shell.execute_reply":"2022-06-26T12:31:23.860464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Looking at the Transformed Data","metadata":{}},{"cell_type":"markdown","source":"##### Helper Function for Converting a batch of Lab images into a batch of RGB images","metadata":{}},{"cell_type":"code","source":"def lab_to_rgb(L, ab):  \n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)","metadata":{"id":"UhCndWvN_0cQ","execution":{"iopub.status.busy":"2022-06-26T12:31:23.862756Z","iopub.execute_input":"2022-06-26T12:31:23.863142Z","iopub.status.idle":"2022-06-26T12:31:23.87431Z","shell.execute_reply.started":"2022-06-26T12:31:23.863113Z","shell.execute_reply":"2022-06-26T12:31:23.873546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = next(iter(train_dl))\nL_Array, ab_Array = data[0], data[1]\nprint(f\"L Array Shape : {L_Array.shape}\", f\"*a*b Array Shape : {ab_Array.shape}\",sep='\\n')\n\nfig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(15,10))\nax0.imshow(L_Array[0][0], cmap='gray')\nax0.set_title('L')\nax1.imshow(ab_Array[0][0])\nax1.set_title('a')\nax2.imshow(ab_Array[0][1])\nax2.set_title('b')\nax3.imshow(lab_to_rgb(L_Array,ab_Array)[0])\nax3.set_title('RGB')\nplt.show()","metadata":{"id":"2DUmaKAT_0cR","outputId":"598be6bc-16d3-4e20-aca2-0de3f83a27e7","scrolled":true,"execution":{"iopub.status.busy":"2022-06-26T12:31:23.875546Z","iopub.execute_input":"2022-06-26T12:31:23.876222Z","iopub.status.idle":"2022-06-26T12:31:26.613225Z","shell.execute_reply.started":"2022-06-26T12:31:23.876186Z","shell.execute_reply":"2022-06-26T12:31:26.611984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4. Modeling the Conditional GAN","metadata":{"id":"x2XVPU7Vy_ad"}},{"cell_type":"markdown","source":"### Generator Model","metadata":{"id":"SRmf-IVSy_ad"}},{"cell_type":"code","source":"class GenBlock(nn.Module):\n    def __init__(self, inputs, outputs, down=True, batchNorm=True, dropout=False):\n        super(GenBlock,self).__init__()\n\n        if down:\n            self.block1 = nn.Conv2d(inputs, outputs, kernel_size=4, stride=2, padding=1, bias=False)\n            self.block4 = nn.LeakyReLU(0.2, True)\n        else:\n            self.block1 = nn.ConvTranspose2d(inputs, outputs, kernel_size=4, stride=2, padding=1, bias=False)\n            self.block4 = nn.ReLU(True)\n        if batchNorm:\n            self.block2 = nn.BatchNorm2d(outputs)\n        if dropout:\n            self.block3 = nn.Dropout(0.5)\n\n        self.batchNorm = batchNorm\n        self.dropout = dropout\n    \n    def forward(self, x):\n        out = self.block1(x)\n        if self.batchNorm:\n            out = self.block2(out)\n        if self.dropout:\n            out = self.block3(out)\n        out = self.block4(out)\n        return out","metadata":{"id":"l-FT6WyC_0cS","execution":{"iopub.status.busy":"2022-06-26T12:31:26.615511Z","iopub.execute_input":"2022-06-26T12:31:26.615959Z","iopub.status.idle":"2022-06-26T12:31:26.629164Z","shell.execute_reply.started":"2022-06-26T12:31:26.615915Z","shell.execute_reply":"2022-06-26T12:31:26.628167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, inputs=1):\n        super(Generator,self).__init__()\n        \n        self.d1=  GenBlock(inputs,64,batchNorm=False)\n        self.d2=  GenBlock(64,128)\n        self.d3=  GenBlock(128,256)\n        self.d4=  GenBlock(256,512)\n        self.d5=  GenBlock(512,512)\n        self.d6=  GenBlock(512,512)\n        self.d7=  GenBlock(512,512)\n        self.d8=  nn.Sequential(nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1, bias=False), nn.LeakyReLU(0.2))\n        \n        \n        self.u1 = GenBlock(512,512,False,dropout=True)\n        self.u2 = GenBlock(1024,512,False,dropout=True)\n        self.u3 = GenBlock(1024,512,False,dropout=True)\n        self.u4 = GenBlock(1024,512,False)\n        self.u5 = GenBlock(1024,256,False)\n        self.u6 = GenBlock(512,128,False)\n        self.u7 = GenBlock(256,64,False)\n        self.u8 = nn.Sequential(nn.ConvTranspose2d(128, 2, kernel_size=4, stride=2, padding=1, bias=False), nn.Tanh())\n        \n    \n    def forward(self, x):\n        dd1 = self.d1(x)\n        dd2 = self.d2(dd1)\n        dd3 = self.d3(dd2)\n        dd4 = self.d4(dd3)\n        dd5 = self.d5(dd4)\n        dd6 = self.d6(dd5)\n        dd7 = self.d7(dd6)\n        dd8 = self.d8(dd7)\n        uu1 = self.u1(dd8)\n        uu2 = self.u2(torch.concat([uu1,dd7],1)) #Skip Connection from dd7 to uu1\n        uu3 = self.u3(torch.concat([uu2,dd6],1))\n        uu4 = self.u4(torch.concat([uu3,dd5],1))\n        uu5 = self.u5(torch.concat([uu4,dd4],1))\n        uu6 = self.u6(torch.concat([uu5,dd3],1))\n        uu7 = self.u7(torch.concat([uu6,dd2],1))\n        uu8 = self.u8(torch.concat([uu7,dd1],1))\n        return uu8","metadata":{"id":"Dp1zsLj0_0cT","execution":{"iopub.status.busy":"2022-06-26T12:31:26.630537Z","iopub.execute_input":"2022-06-26T12:31:26.631039Z","iopub.status.idle":"2022-06-26T12:31:26.653113Z","shell.execute_reply.started":"2022-06-26T12:31:26.631005Z","shell.execute_reply":"2022-06-26T12:31:26.651861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Generator Model Summary","metadata":{}},{"cell_type":"code","source":"!pip install -U torchsummary\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:31:26.656973Z","iopub.execute_input":"2022-06-26T12:31:26.657973Z","iopub.status.idle":"2022-06-26T12:31:37.732639Z","shell.execute_reply.started":"2022-06-26T12:31:26.657934Z","shell.execute_reply":"2022-06-26T12:31:37.731376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen=Generator(1)\nsummary(gen,(1,ImageSize,ImageSize),BatchSize)","metadata":{"id":"GE5N51mu_0cT","outputId":"bbaa772b-d565-45a8-dcd6-dadae79ca5ce","execution":{"iopub.status.busy":"2022-06-26T12:31:37.734435Z","iopub.execute_input":"2022-06-26T12:31:37.734814Z","iopub.status.idle":"2022-06-26T12:31:38.575264Z","shell.execute_reply.started":"2022-06-26T12:31:37.734779Z","shell.execute_reply":"2022-06-26T12:31:38.574173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discriminator Model","metadata":{"id":"ENAlu2qhy_af"}},{"cell_type":"code","source":"class DiscBlock(nn.Module):\n    def __init__(self, inputs, outputs,  kernel=4, stride=2, padding=1, batchNorm=True, activation=True):\n        super(DiscBlock,self).__init__()\n        \n        self.block1 = nn.Conv2d(inputs, outputs, kernel, stride, padding, bias=not batchNorm)\n        if batchNorm: self.block2 = nn.BatchNorm2d(outputs)\n        if activation: self.block3 = nn.LeakyReLU(0.2, True)\n\n        self.batchNorm = batchNorm\n        self.activation = activation\n\n\n    def forward(self, x):\n        out = self.block1(x)\n        if self.batchNorm:\n            out = self.block2(out)\n        if self.activation:\n            out = self.block3(out)\n        # print(out.shape)\n        return out\n        \n\nclass Discriminator(nn.Module):\n    def __init__(self, inputs=3):\n        super(Discriminator,self).__init__()\n\n        self.b1 = DiscBlock(inputs,64,batchNorm=False)\n        self.b2 = DiscBlock(64,128)\n        self.b3 = DiscBlock(128,256)\n        self.b4 = DiscBlock(256,512,stride=1)\n        self.b5 = DiscBlock(512,1,stride=1,batchNorm=False,activation=False)\n                                \n    def forward(self, x):\n        #print(x.shape())\n        y1 = self.b1(x)\n        y2 = self.b2(y1)\n        y3 = self.b3(y2)\n        y4 = self.b4(y3)\n        y5 = self.b5(y4)\n        return y5","metadata":{"id":"z7WMzOvy_0cU","execution":{"iopub.status.busy":"2022-06-26T12:31:38.577569Z","iopub.execute_input":"2022-06-26T12:31:38.578064Z","iopub.status.idle":"2022-06-26T12:31:38.591619Z","shell.execute_reply.started":"2022-06-26T12:31:38.578015Z","shell.execute_reply":"2022-06-26T12:31:38.590449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Discriminator Model Summary","metadata":{}},{"cell_type":"code","source":"testDiscriminator=Discriminator(3)\nsummary(testDiscriminator,(3,256,256),16)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:31:38.593018Z","iopub.execute_input":"2022-06-26T12:31:38.593383Z","iopub.status.idle":"2022-06-26T12:31:38.756739Z","shell.execute_reply.started":"2022-06-26T12:31:38.593331Z","shell.execute_reply":"2022-06-26T12:31:38.755765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5. Defining Helper Functions","metadata":{}},{"cell_type":"markdown","source":"#### For Generating Some Predictions","metadata":{}},{"cell_type":"code","source":"def ShowSamples(Model, dl, folder, epoch= -1, SAVE = True,suffix=\"\"):\n    data = next(iter(dl))\n    L, ab = data[0], data[1]\n    L=L.to(device)\n    ab=ab.to(device)\n    # print(ab.shape)\n    #Setting Model to Evaluation Mode.\n    Model.eval()\n    with torch.no_grad():\n        ab_gen = Model(L)\n    Model.train()\n    real_imgs = lab_to_rgb(L, ab)\n    fake_imgs = lab_to_rgb(L, ab_gen.detach())\n\n    fig = plt.figure(figsize=(15, 8))\n    for i in range(5):\n        ax = plt.subplot(3, 5, i + 1)\n        ax.imshow(L[i][0].cpu(), cmap='gray')\n        if i==0:\n            ax.set_ylabel('Grayscale', size='large')\n        ax = plt.subplot(3, 5, i + 1 + 5)\n        ax.imshow(fake_imgs[i])\n        if i==0:\n            ax.set_ylabel('Prediction', size='large')\n        ax = plt.subplot(3, 5, i + 1 + 10)\n        ax.imshow(real_imgs[i])\n        if i==0:\n            ax.set_ylabel('Ground Truth', size='large')\n    plt.show()\n    if SAVE:\n        now = datetime.now()\n        current_time = now.strftime(\"%H:%M:%S\")\n        fig.savefig(folder + f\"/Results_After_Epoch_{epoch}{suffix}_{current_time}.png\")","metadata":{"id":"mVgOawBCGXUJ","execution":{"iopub.status.busy":"2022-06-26T12:35:38.647621Z","iopub.execute_input":"2022-06-26T12:35:38.648171Z","iopub.status.idle":"2022-06-26T12:35:38.66261Z","shell.execute_reply.started":"2022-06-26T12:35:38.648134Z","shell.execute_reply":"2022-06-26T12:35:38.661481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### For Visualizing Loss","metadata":{}},{"cell_type":"code","source":"def VisualizeLoss(Loss_Arr, folder, epoch, generator = True, SAVE = True):\n    x=(range(0,len(Loss_Arr)))\n    plt.figure(figsize = (12,10))\n    plt.plot(x,Loss_Arr)\n    str = \"Discriminator\"\n    if generator:\n        str = \"Generator\"\n    plt.xlabel(\"Number of Iterations\")\n    plt.ylabel(str + \" Loss\")\n    if SAVE:\n        plt.savefig(folder + f\"/{str}_Loss_After_Epoch_{epoch}.png\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:35:41.671237Z","iopub.execute_input":"2022-06-26T12:35:41.671684Z","iopub.status.idle":"2022-06-26T12:35:41.679493Z","shell.execute_reply.started":"2022-06-26T12:35:41.671649Z","shell.execute_reply":"2022-06-26T12:35:41.678375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6. Initializing The Model","metadata":{"id":"NvANwjzEy_ah"}},{"cell_type":"markdown","source":"### Defining Some Hyperparameters","metadata":{}},{"cell_type":"code","source":"LEARNING_RATE = 2e-4\nEPOCHS = 650\nLAMBDA = 100 #Discriminator L1 Loss Hyperparameter as Defined in the Pix2Pix Paper \nepoch = 1\nBETAS = (0.5,0.999) #Optimizer Hyperparameter as Defined in the Pix2Pix Paper\nlossOfDiscriminator = []\nlossOfGenerator = []\nsaveImages = False #To Save Images during visualization","metadata":{"id":"1m7gJ8uA_0cV","execution":{"iopub.status.busy":"2022-06-26T12:31:38.790282Z","iopub.execute_input":"2022-06-26T12:31:38.790982Z","iopub.status.idle":"2022-06-26T12:31:38.816996Z","shell.execute_reply.started":"2022-06-26T12:31:38.790942Z","shell.execute_reply":"2022-06-26T12:31:38.81584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functions and Logic for Loading and Saving Checkpoints","metadata":{}},{"cell_type":"code","source":"inputFolder = \"../input/model-params\"\noutputFolder = \"/kaggle/working\"\ncheckpointPathDiscriminator = inputFolder+\"/disc.pth.tar\"\ncheckpointPathGenerator = inputFolder+\"/gen.pth.tar\"\nloadModel = True","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:31:38.818263Z","iopub.execute_input":"2022-06-26T12:31:38.818971Z","iopub.status.idle":"2022-06-26T12:31:38.823742Z","shell.execute_reply.started":"2022-06-26T12:31:38.818897Z","shell.execute_reply":"2022-06-26T12:31:38.822695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SaveCheckpoint(model, optimizer, epoch, filename):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n        \"epoch\":epoch,\n        \"DISC_LOSS\" : lossOfDiscriminator,\n        \"GEN_LOSS\" : lossOfGenerator\n    }\n    torch.save(checkpoint, filename)\n\ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=device)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    global epoch\n    global lossOfDiscriminator\n    global lossOfGenerator\n    epoch = checkpoint[\"epoch\"]\n    lossOfDiscriminator = checkpoint[\"DISC_LOSS\"].copy()\n    lossOfGenerator = checkpoint[\"GEN_LOSS\"].copy()\n\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr","metadata":{"id":"v37vqCDzy_ai","execution":{"iopub.status.busy":"2022-06-26T12:31:38.825061Z","iopub.execute_input":"2022-06-26T12:31:38.825429Z","iopub.status.idle":"2022-06-26T12:31:38.838907Z","shell.execute_reply.started":"2022-06-26T12:31:38.825391Z","shell.execute_reply":"2022-06-26T12:31:38.83775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Initializing Models","metadata":{}},{"cell_type":"code","source":"disc = Discriminator(3).to(device)\ngen = Generator(1).to(device)\noptimizerForDiscriminator = optim.Adam(disc.parameters(),lr=LEARNING_RATE, betas=BETAS)\noptimizerForGenerator = optim.Adam(gen.parameters(),lr=LEARNING_RATE, betas=BETAS)\nLossFunction = nn.BCEWithLogitsLoss()\nL1_Loss = nn.L1Loss()\n#Float 16 Training for faster Training\ndiscriminatorScaler = torch.cuda.amp.GradScaler()\ngeneratorScaler = torch.cuda.amp.GradScaler()","metadata":{"id":"oZ5efnjZ_0cV","outputId":"8acc8836-fb51-4291-8bff-a6b12f1fbe5d","execution":{"iopub.status.busy":"2022-06-26T12:31:38.840221Z","iopub.execute_input":"2022-06-26T12:31:38.840565Z","iopub.status.idle":"2022-06-26T12:31:39.349511Z","shell.execute_reply.started":"2022-06-26T12:31:38.840536Z","shell.execute_reply":"2022-06-26T12:31:39.348398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading Previously Saved Checkpoint if Applicable","metadata":{}},{"cell_type":"code","source":"if loadModel:\n    load_checkpoint(checkpointPathGenerator, gen, optimizerForGenerator, LEARNING_RATE)\n    load_checkpoint(checkpointPathDiscriminator, disc, optimizerForDiscriminator, LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:31:39.350834Z","iopub.execute_input":"2022-06-26T12:31:39.351173Z","iopub.status.idle":"2022-06-26T12:31:41.794027Z","shell.execute_reply.started":"2022-06-26T12:31:39.351143Z","shell.execute_reply":"2022-06-26T12:31:41.793015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SaveModel = True\ncheckpointPathDiscriminator = outputFolder+\"/disc.pth.tar\"\ncheckpointPathGenerator = outputFolder+\"/gen.pth.tar\"","metadata":{"id":"BoMozGvszMP4","execution":{"iopub.status.busy":"2022-06-26T12:31:41.795439Z","iopub.execute_input":"2022-06-26T12:31:41.795783Z","iopub.status.idle":"2022-06-26T12:31:41.80077Z","shell.execute_reply.started":"2022-06-26T12:31:41.795753Z","shell.execute_reply":"2022-06-26T12:31:41.799601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 7. Training","metadata":{}},{"cell_type":"code","source":"def TrainFunction(disc, gen, loader, opt_disc, opt_gen, l1_loss, BCE_Loss, gen_scaler, disc_scaler):\n    loop = tqdm(loader, leave=True)\n    for idx, (L, ab) in enumerate(loop):\n        L = L.to(device)\n        ab = ab.to(device)\n        \n        # Train Discriminator\n        with torch.cuda.amp.autocast():\n            y_fake = gen(L)\n            D_real = disc(torch.concat([L, ab],1))\n            D_real_loss = BCE_Loss(D_real, torch.ones_like(D_real))\n            D_fake = disc(torch.concat([L, y_fake.detach()],1))\n            D_fake_loss = BCE_Loss(D_fake, torch.zeros_like(D_fake))\n            D_loss = (D_real_loss + D_fake_loss) / 2\n            lossOfDiscriminator.append(D_loss.item())\n        disc.zero_grad()\n        disc_scaler.scale(D_loss).backward()\n        disc_scaler.step(opt_disc)\n        disc_scaler.update()\n        \n        # Train generator\n        with torch.cuda.amp.autocast():\n            D_fake = disc(torch.concat([L, y_fake],1))\n            G_fake_loss = BCE_Loss(D_fake, torch.ones_like(D_fake))\n            L1 = l1_loss(y_fake, ab) * LAMBDA\n            G_loss = G_fake_loss + L1\n            lossOfGenerator.append(G_loss.item())\n\n        opt_gen.zero_grad()\n        gen_scaler.scale(G_loss).backward()\n        gen_scaler.step(opt_gen)\n        gen_scaler.update()","metadata":{"id":"r_AsMYLm_0cW","execution":{"iopub.status.busy":"2022-06-26T12:31:41.802009Z","iopub.execute_input":"2022-06-26T12:31:41.802299Z","iopub.status.idle":"2022-06-26T12:31:41.814466Z","shell.execute_reply.started":"2022-06-26T12:31:41.802272Z","shell.execute_reply":"2022-06-26T12:31:41.81353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"while epoch <= EPOCHS:\n    print(\"\\nEpoch\",epoch,'\\n')\n    ShowSamples(gen, val_dl,outputFolder,epoch,saveImages)\n\n    if SaveModel:\n        SaveCheckpoint(gen, optimizerForGenerator, epoch, filename=checkpointPathGenerator)\n        SaveCheckpoint(disc, optimizerForDiscriminator, epoch, filename=checkpointPathDiscriminator)\n\n    if epoch%2==0:\n        print(\"Generator Loss\\n\")\n        VisualizeLoss(lossOfGenerator,outputFolder,epoch,True,saveImages)\n        print(\"Discriminator Loss\\n\")\n        VisualizeLoss(lossOfDiscriminator,outputFolder,epoch,False,saveImages)\n\n    TrainFunction(disc, gen, train_dl, optimizerForDiscriminator, optimizerForGenerator, L1_Loss, LossFunction, discriminatorScaler, generatorScaler)\n    epoch+=1\n","metadata":{"id":"OOw91Hw1_0cX","outputId":"ff55b546-d7f2-4c45-b958-7896d7d7ac57","execution":{"iopub.status.busy":"2022-06-26T12:31:41.816108Z","iopub.execute_input":"2022-06-26T12:31:41.818127Z","iopub.status.idle":"2022-06-26T12:32:01.636046Z","shell.execute_reply.started":"2022-06-26T12:31:41.818082Z","shell.execute_reply":"2022-06-26T12:32:01.627646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 8. Visualizing Loss Trajectory","metadata":{}},{"cell_type":"markdown","source":"### Generator Loss","metadata":{}},{"cell_type":"code","source":"VisualizeLoss(lossOfGenerator,outputFolder,epoch,True,SAVE=False)","metadata":{"id":"lPAmUO2hy_aj","execution":{"iopub.status.busy":"2022-06-26T12:32:01.643064Z","iopub.status.idle":"2022-06-26T12:32:01.644566Z","shell.execute_reply.started":"2022-06-26T12:32:01.643541Z","shell.execute_reply":"2022-06-26T12:32:01.643652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discriminator Loss","metadata":{}},{"cell_type":"code","source":"VisualizeLoss(lossOfDiscriminator,outputFolder,epoch,False,SAVE=False)","metadata":{"id":"BBUKf0f_y_ak","execution":{"iopub.status.busy":"2022-06-26T12:32:01.648781Z","iopub.status.idle":"2022-06-26T12:32:01.650106Z","shell.execute_reply.started":"2022-06-26T12:32:01.649085Z","shell.execute_reply":"2022-06-26T12:32:01.649169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 9. Visualizing Predictions","metadata":{}},{"cell_type":"markdown","source":"### Predictions on Training Data","metadata":{}},{"cell_type":"code","source":"numRuns = 5 #Generate numRuns*5 Samples","metadata":{"execution":{"iopub.status.busy":"2022-06-26T12:32:14.881796Z","iopub.execute_input":"2022-06-26T12:32:14.882635Z","iopub.status.idle":"2022-06-26T12:32:14.887862Z","shell.execute_reply.started":"2022-06-26T12:32:14.882589Z","shell.execute_reply":"2022-06-26T12:32:14.886869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for run in range(numRuns):\n    ShowSamples(gen, train_dl,outputFolder,epoch,SAVE=True,suffix=\"_On_Training_Set\")","metadata":{"id":"rpQkJkho5AS_","outputId":"61bc149a-cbd4-4db6-e12a-ada766b25e82","execution":{"iopub.status.busy":"2022-06-26T12:35:48.261106Z","iopub.execute_input":"2022-06-26T12:35:48.261594Z","iopub.status.idle":"2022-06-26T12:36:22.995691Z","shell.execute_reply.started":"2022-06-26T12:35:48.261554Z","shell.execute_reply":"2022-06-26T12:36:22.994442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions on Validation Data","metadata":{}},{"cell_type":"code","source":"for run in range(numRuns):\n    ShowSamples(gen, val_dl,outputFolder,epoch,SAVE=False)","metadata":{"id":"j_VTRqy3S35s","outputId":"35fa615f-7b51-4be7-9b15-15844eb8cf08","execution":{"iopub.status.busy":"2022-06-26T12:32:51.022015Z","iopub.execute_input":"2022-06-26T12:32:51.022347Z","iopub.status.idle":"2022-06-26T12:33:24.171633Z","shell.execute_reply.started":"2022-06-26T12:32:51.022319Z","shell.execute_reply":"2022-06-26T12:33:24.170568Z"},"trusted":true},"execution_count":null,"outputs":[]}]}